{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "maotj_8FNEyt",
        "oAzFEEsrM__p",
        "uhlklxRrNX0X"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshsingh0206/nlp/blob/main/Preprocess_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4 # in case you don't have it installed\n",
        "!pip install contractions"
      ],
      "metadata": {
        "id": "GlnYpR7nRg9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "import collections\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "8ZLNwgOzrc73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap-JHbJfn6kp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP\\ Dataset/"
      ],
      "metadata": {
        "id": "Jx3oW3SDoIAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yahoo Dataset"
      ],
      "metadata": {
        "id": "Pun1qDcaNueH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yahooquery"
      ],
      "metadata": {
        "id": "Lz7bud5FOvg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install yahooquery\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from yahooquery import Ticker\n",
        "\n",
        "def date_range(current_date, num_days=10):\n",
        "    \"\"\"Helper function to get x number of days before and after the current date\n",
        "\n",
        "    Args:\n",
        "        current_date (str): Current date in YYYY-MM-DD format\n",
        "        num_days (int): Number of days by which the `current_date` is incremented and decremented\n",
        "\n",
        "    Returns:\n",
        "        list: List of dates in the sepcified interval\n",
        "    \"\"\"\n",
        "    num_days = num_days + 1 # Adding 1 because the current date is included in the interval\n",
        "    base = datetime.strptime(current_date, '%Y-%m-%d')\n",
        "\n",
        "    \n",
        "    # Previous `x` days --> 06, 05, 04 (base is 06)\n",
        "    date_list_prev = [(base - timedelta(days=x)).strftime('%Y-%m-%d') for x in range(num_days)]\n",
        "    # Next `x` days     --> 06, 07, 08 (base is 06)\n",
        "    date_list_next = [(base + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(num_days)]\n",
        "    \n",
        "    # [06, 05, 04][::-1] + [06, 07, 08][1:]\n",
        "    # return date_list_prev[::-1] + date_list_next[1:]\n",
        "    return date_list_prev[::-1]\n",
        "\n",
        "def get_close_prices(ticker, current_date, num_days=10):\n",
        "    \"\"\"Return a list of close prices for every day in the given range of startdate and enddate\n",
        "\n",
        "    Args:\n",
        "        ticker (str): Company ticker\n",
        "        current_date (str): Date (YYYY-MM-DD) for which we need the previous and next 10 close prices\n",
        "        num_days (str): Number of days offset. Defaults to 10\n",
        "\n",
        "    Returns:\n",
        "        list: List of close prices\n",
        "    \"\"\"\n",
        "    tuples = []\n",
        "    close_prices = []\n",
        "    first_open = 0\n",
        "\n",
        "    # Get list of dates for which close price is to be calculated\n",
        "    dates = date_range(current_date=current_date, num_days=num_days)\n",
        "    start_date = dates[0]\n",
        "    end_date = dates[-1]\n",
        "\n",
        "    # Get close prices\n",
        "    ticker = ticker.lower()\n",
        "    ticker = Ticker(ticker, asynchronous=True)\n",
        "    df = ticker.history(start=start_date, end=end_date)\n",
        "\n",
        "    # Group data -> [(date, price), (date, price), ...]\n",
        "    for index, row in df.iterrows():\n",
        "        # To handle the case where the first price is zero\n",
        "        # Initialize with open price of the next day\n",
        "        if first_open == 0:\n",
        "            first_open = row['open']\n",
        "        date = index[1].strftime('%Y-%m-%d')\n",
        "        tuples.append((date, row['close']))\n",
        "    \n",
        "    curr_price = first_open\n",
        "    \n",
        "    # `dates` is a super set of `close_prices`\n",
        "    # For every date if there is no close price we take the previus price\n",
        "    j = 0\n",
        "    for i in range(len(dates)):\n",
        "        if j < len(tuples) and tuples[j][0] == dates[i]:\n",
        "            curr_price = tuples[j][1]\n",
        "            close_prices.append(curr_price)\n",
        "            j = j + 1\n",
        "        else:\n",
        "            close_prices.append(curr_price)\n",
        "\n",
        "    return close_prices\n",
        "\n",
        "def yahoo_data(current_date):\n",
        "    # Date for which we need the previous and next 10 close prices\n",
        "    # current_date = '1999-06-06'\n",
        "    # Number of days by which the `current_date` is incremented and decremented\n",
        "    num_days = 10\n",
        "    \n",
        "    prices = get_close_prices(ticker='^gspc', current_date=current_date, num_days=num_days)\n",
        "    # print('Length: {}\\n\\nPrices:\\n{}'.format(len(prices), prices))\n",
        "    return prices\n"
      ],
      "metadata": {
        "id": "4oByYUXfNyHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Reuters and Bloomberg CSV"
      ],
      "metadata": {
        "id": "maotj_8FNEyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = pd.DataFrame(columns=['ts', 'title', 'src'])\n",
        "for filename in tqdm(os.listdir(\"./reuters 2/\")):\n",
        "  df = pd.read_csv(\"reuters 2/\" + filename, sep='\\t', usecols=[0,1])\n",
        "  df['src'] = 'reuters'\n",
        "  newdf = newdf.append(df, ignore_index=True)"
      ],
      "metadata": {
        "id": "2hNeUU7hoQMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf"
      ],
      "metadata": {
        "id": "27vTiR0lwlgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, v in enumerate(newdf['ts']):\n",
        "  date = v.split(' ')[0]\n",
        "  y = date[:4]\n",
        "  m = date[4:6]\n",
        "  d = date[6:]\n",
        "  newdf.at[idx, 'ts'] = y + \"-\" + m + \"-\" + d"
      ],
      "metadata": {
        "id": "khb3OYqHyJSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf"
      ],
      "metadata": {
        "id": "n7reAkD9zzku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.to_csv('./reuters.csv')"
      ],
      "metadata": {
        "id": "DXJSQ5lN5H-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ./20061020_20131126_bloomberg_news\\ 2.zip"
      ],
      "metadata": {
        "id": "bQGSyLG85WNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "\n",
        "for folder in tqdm(sorted(os.listdir(\"./20061020_20131126_bloomberg_news 2/\"), reverse=True)):\n",
        "  for filename in os.listdir(\"./20061020_20131126_bloomberg_news 2/\"+folder):\n",
        "    file1 = open('./20061020_20131126_bloomberg_news 2/'+folder+'/'+filename, 'r')\n",
        "    lines = file1.readlines()\n",
        "    row = []\n",
        "    for idx, line in enumerate(lines):\n",
        "      if idx == 0:\n",
        "        row.append(line[3:-1])\n",
        "      if idx == 2:\n",
        "        row.append(line.split('T')[0][3:])\n",
        "        break\n",
        "    row = row[::-1]\n",
        "    res.append(row)"
      ],
      "metadata": {
        "id": "ouIgbHv75s7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(res)"
      ],
      "metadata": {
        "id": "dmWJH1qBzNUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df = pd.DataFrame(res, columns = ['ts', 'title', 'src'])"
      ],
      "metadata": {
        "id": "a4qUWHp00KVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df"
      ],
      "metadata": {
        "id": "6Of0WfE60v3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df.to_csv('./bloomberg.csv')"
      ],
      "metadata": {
        "id": "BUDtOXUs1Dit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge Data"
      ],
      "metadata": {
        "id": "oAzFEEsrM__p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df = pd.read_csv('./bloomberg.csv', index_col=0)\n",
        "bloomberg_df"
      ],
      "metadata": {
        "id": "vcjtVQJLM7sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df = pd.read_csv('./reuters.csv', index_col=0)\n",
        "reuters_df"
      ],
      "metadata": {
        "id": "twFmb6Ks3h0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.DataFrame(columns=['ts', 'title', 'src'])\n",
        "merged_df = merged_df.append(bloomberg_df, ignore_index=True)\n",
        "merged_df = merged_df.append(reuters_df, ignore_index=True)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "9n2133Rs33li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.shape"
      ],
      "metadata": {
        "id": "Of3qG5Dm4RhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('../merged.csv')"
      ],
      "metadata": {
        "id": "NesKD98A5Mur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "uhlklxRrNX0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df = pd.read_csv('./bloomberg.csv', index_col=0)\n",
        "bloomberg_df"
      ],
      "metadata": {
        "id": "xF25VnKqNa1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df = pd.read_csv('./reuters.csv', index_col=0)\n",
        "reuters_df"
      ],
      "metadata": {
        "id": "n6Id1FyDNdgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv('./merged.csv', index_col=0)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "vMOLi9hMNd9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateAverage(df, reviewBody, cleanBody):\n",
        "  originalUncleanedAverage=df[reviewBody].apply(lambda x: len(x)).mean()\n",
        "  originalCleanedAverage=df[cleanBody].apply(lambda x: len(x)).mean()\n",
        "  print(f'Original uncleaned reviews had an average length of ${originalUncleanedAverage}')\n",
        "  print(f'New cleaned reviews had an average length of ${originalCleanedAverage}')"
      ],
      "metadata": {
        "id": "wrhlaeCrVkpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuations = '''!()-[]{};:\"\\,<>./?@#%^&*_~'''\n",
        "def cleanText(x):\n",
        "  x = x.lower().strip()\n",
        "  soup = BeautifulSoup(x)\n",
        "  x = soup.get_text()\n",
        "  x = re.sub(r'https?://\\S+', '', x)\n",
        "  x=re.sub(\"\\s\\s+\", \" \", x.strip())\n",
        "  # x=re.sub(\"[^a-zA-Z\\s]+\", \" \", x)\n",
        "\n",
        "  no_punct = \"\"\n",
        "  for char in x:\n",
        "    if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        "    else:\n",
        "        no_punct += \" \"\n",
        "  x = no_punct\n",
        "\n",
        "  x=re.sub(\"\\s\\s+\", \" \", x.strip())\n",
        "  if (x==' ' or len(x)==0): \n",
        "    return np.nan\n",
        "  return x"
      ],
      "metadata": {
        "id": "sRfcDEQkQLYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df['clean_title'] = reuters_df['title'].apply(cleanText)"
      ],
      "metadata": {
        "id": "iC69MxFwRAr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df.dropna(inplace=True)\n",
        "reuters_df.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "gtGtUQa7Q9hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df"
      ],
      "metadata": {
        "id": "ERaJggYOWbNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculateAverage(reuters_df, 'title', 'clean_title')"
      ],
      "metadata": {
        "id": "yixukAitVoRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "imR0zhUZk0fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df['clean_title'] = bloomberg_df['title'].apply(cleanText)\n",
        "bloomberg_df.dropna(inplace=True)\n",
        "bloomberg_df.reset_index(inplace=True)\n",
        "bloomberg_df"
      ],
      "metadata": {
        "id": "d5uXd8HQVXJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculateAverage(bloomberg_df, 'title', 'clean_title')"
      ],
      "metadata": {
        "id": "TJlh802qhoeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df = bloomberg_df.drop('index', axis=1)"
      ],
      "metadata": {
        "id": "A9rLPnANlNT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bloomberg_df"
      ],
      "metadata": {
        "id": "YRcOUkhUoc2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_df.to_csv('./reuters_clean.csv')\n",
        "bloomberg_df.to_csv('./bloomberg_clean.csv')"
      ],
      "metadata": {
        "id": "sMVkZxYAlnaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.DataFrame(columns=['ts', 'title', 'src', 'clean_title'])\n",
        "merged_df = merged_df.append(bloomberg_df, ignore_index=True)\n",
        "merged_df = merged_df.append(reuters_df, ignore_index=True)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "OnApTUpYmITV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('./merged_clean.csv')"
      ],
      "metadata": {
        "id": "uq4XNlL6mgip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating final data with Yahoo values"
      ],
      "metadata": {
        "id": "hNizofral6OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.read_csv('./merged_clean.csv', index_col=0)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "zCcQzdCbmGME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = merged_df.sort_values('ts', ascending=False, ignore_index=True)"
      ],
      "metadata": {
        "id": "e09_5-8vl4fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "hNI0Q_wJnNwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df2.drop(df2.index[[0,1,2]])\n",
        "df2.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Ayqu1XdpoBRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop('index', axis=1)\n",
        "df2"
      ],
      "metadata": {
        "id": "kTvieiE9oshA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('./merged_clean_sorted.csv')"
      ],
      "metadata": {
        "id": "nwML8Ctcse9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('./merged_clean_sorted.csv', index_col=0)\n",
        "df2"
      ],
      "metadata": {
        "id": "OF6TjhGNJyoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['ts'].value_counts().sort_values(ascending=True) "
      ],
      "metadata": {
        "id": "cmLdKVRq3kvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df2['ts'].value_counts())"
      ],
      "metadata": {
        "id": "-ujCOj-V3F1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = collections.defaultdict(list)\n",
        "cnt = collections.defaultdict(lambda: 0)\n",
        "\n",
        "for index, row in tqdm(df2.iterrows()):\n",
        "    if cnt[row['ts']]>400:\n",
        "      continue\n",
        "    else:\n",
        "      if row['ts'] in m:\n",
        "        for idx, i in enumerate(m[row['ts']]):\n",
        "          df2.loc[index,'p'+str(idx)] = i\n",
        "      else:\n",
        "        yd = yahoo_data(row['ts'])\n",
        "        for idx, i in enumerate(yd):\n",
        "          df2.loc[index,'p'+str(idx)] = i\n",
        "          m[row['ts']] = yd\n",
        "      cnt[row['ts']] += 1"
      ],
      "metadata": {
        "id": "7tLRP8J2QdoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "4iM7hEzBQkOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = collections.defaultdict(list)\n",
        "cnt = collections.defaultdict(lambda: 0)\n",
        "\n",
        "for index, row in tqdm(df2.iterrows()):\n",
        "    if cnt[row['ts']]>400:\n",
        "      continue\n",
        "    else:\n",
        "      if row['ts'] in m:\n",
        "        for idx, i in enumerate(m[row['ts']]):\n",
        "          df2.loc[index,'p'+str(idx)] = i\n",
        "      else:\n",
        "        yd = yahoo_data(row['ts'])\n",
        "        for idx, i in enumerate(yd):\n",
        "          df2.loc[index,'p'+str(idx)] = i\n",
        "          m[row['ts']] = yd\n",
        "      cnt[row['ts']] += 1"
      ],
      "metadata": {
        "id": "Xki-8H6op_w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.dropna()\n",
        "df2.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "oMx-8naUJ_Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.drop('index', axis=1)\n",
        "df2"
      ],
      "metadata": {
        "id": "7HVv4hHCE9gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('./final_data.csv')"
      ],
      "metadata": {
        "id": "d5fa5wRHN5Ny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}